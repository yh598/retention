from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, when, rand
from pyspark.ml.feature import Imputer, StringIndexer, VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.model_selection import RandomizedSearchCV
from sklearn.utils import resample
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix
import shap
import lime
import lime.lime_tabular
from pdpbox import pdp, info_plots
from scipy.stats import ks_2samp

# Initialize Spark Session
spark = SparkSession.builder.appName("Churn Prediction").getOrCreate()

# Load Dataset
file_path = "path/to/large_dataset.csv"
df = spark.read.csv(file_path, header=True, inferSchema=True)

# Drop High Null Columns (Threshold: >50% missing values)
null_threshold = 0.5 * df.count()
high_null_cols = [col_name for col_name in df.columns if df.select(count(when(col(col_name).isNull(), 1))).collect()[0][0] > null_threshold]
df = df.drop(*high_null_cols)

# Drop High-Cardinality and Irrelevant Columns
drop_cols = ['PERSON_PERIOD_ID', 'PERSON_PERIOD_ID_HASH', 'STUDY_START_DT', 'STUDY_END_DT', 'FIRST_ELIG_MONTH_START_DT', 'ACO_NAME', 'PROV_IPA_NAME', 'PROV_PMT_MDL_NM']
df = df.drop(*drop_cols)

# Identify Numerical and Categorical Columns
numeric_cols = [col_name for col_name, dtype in df.dtypes if dtype in ('int', 'double')]
categorical_cols = [col_name for col_name, dtype in df.dtypes if dtype == 'string']

# Handle Missing Values for Numerical Columns
num_imputer = Imputer(strategy="median", inputCols=numeric_cols, outputCols=[col + "_imputed" for col in numeric_cols])
df = num_imputer.fit(df).transform(df)

# Encode Categorical Variables
for col_name in categorical_cols:
    indexer = StringIndexer(inputCol=col_name, outputCol=col_name + "_index").fit(df)
    df = indexer.transform(df)
df = df.drop(*categorical_cols, *numeric_cols)

# Assemble Features
feature_cols = [col for col in df.columns if col != "churn_flag"]
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
df = assembler.transform(df).select("features", "churn_flag")

# Train-Test Split (Time-Based)
df = df.withColumn("year", df["STUDY_END_DT"].substr(1, 4).cast("int"))
train_df = df.filter(df.year <= 2023).drop("year")
test_df = df.filter(df.year == 2024).drop("year")
train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)

# Balance Training Data (Undersampling for Churn Prediction)
class_counts = train_df.groupBy("churn_flag").count().collect()
min_class_count = min([row["count"] for row in class_counts])
balanced_train_df = train_df.sampleBy("churn_flag", fractions={0: min_class_count / class_counts[0]["count"], 1: min_class_count / class_counts[1]["count"]}, seed=42)

# Train Initial Random Forest Model
rf = RandomForestClassifier(featuresCol="features", labelCol="churn_flag", numTrees=100)
model = rf.fit(balanced_train_df)

# Extract Feature Importance
feature_importance = np.array(model.featureImportances.toArray())
top_features_df = pd.DataFrame({'Feature': feature_cols, 'Importance': feature_importance}).sort_values(by="Importance", ascending=False).head(20)

# Select Top 20 Features
top_20_features = top_features_df['Feature'].tolist()
assembler = VectorAssembler(inputCols=top_20_features, outputCol="features")
df = assembler.transform(df).select("features", "churn_flag")

# Retrain Model with Top 20 Features
train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
rf_final = RandomForestClassifier(featuresCol="features", labelCol="churn_flag", numTrees=100)
final_model = rf_final.fit(train_df)

# Model Evaluation
predictions = final_model.transform(test_df)
evaluator = BinaryClassificationEvaluator(labelCol="churn_flag", rawPredictionCol="prediction", metricName="areaUnderROC")
auc = evaluator.evaluate(predictions)
print(f"AUC-ROC: {auc}")

# Lift Table
test_pandas = test_df.toPandas()
test_pandas['predicted_prob'] = final_model.transform(test_df).select('probability').rdd.map(lambda x: x[0][1]).collect()
test_pandas = test_pandas.sort_values(by='predicted_prob', ascending=False)
test_pandas['decile'] = pd.qcut(test_pandas['predicted_prob'], 10, labels=False)
lift_table = test_pandas.groupby('decile').agg({'churn_flag': ['count', 'sum']})
lift_table.columns = ['Total', 'Retained']
lift_table['Churn Rate'] = lift_table['Retained'] / lift_table['Total']
print(lift_table)

# KS Statistic
ks_stat, ks_p_value = ks_2samp(test_pandas[test_pandas['churn_flag'] == 1]['predicted_prob'], test_pandas[test_pandas['churn_flag'] == 0]['predicted_prob'])
print(f"KS Statistic: {ks_stat}, p-value: {ks_p_value}")

# Save Model
model_path = "path/to/save_model"
final_model.save(model_path)

# Feature Importance Plot
plt.figure(figsize=(10, 6))
plt.barh(top_features_df['Feature'], top_features_df['Importance'], align='center')
plt.xlabel("Feature Importance")
plt.ylabel("Feature Name")
plt.title("Top 20 Most Important Features for Retention Prediction")
plt.gca().invert_yaxis()
plt.show()

# SHAP Explanation
explainer = shap.TreeExplainer(best_rf_model)
shap_values = explainer.shap_values(X_train_pandas)
shap.summary_plot(shap_values, X_train_pandas)

# LIME Explanation
lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train_pandas, feature_names=top_20_features, class_names=['Not Retained', 'Retained'], mode='classification')
exp = lime_explainer.explain_instance(X_train_pandas[0], best_rf_model.predict_proba)
exp.show_in_notebook()

# PDP Explanation
pdp_feature = pdp.pdp_isolate(model=best_rf_model, dataset=pd.DataFrame(X_train_pandas, columns=top_20_features), model_features=top_20_features, feature=top_20_features[0])
pdp.pdp_plot(pdp_feature, top_20_features[0])
plt.show()
